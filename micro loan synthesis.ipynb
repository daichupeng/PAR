{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16f1261f-e773-4dd3-9f94-88aaa326360f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  weather_forecast_severity  ticket_sales_ratio       event_type  \\\n",
      "0                light_rain                0.49  community_event   \n",
      "1                     clear                0.29       exhibition   \n",
      "2                heavy_rain                0.39          concert   \n",
      "3                light_rain                0.61          concert   \n",
      "4                     clear                0.74         festival   \n",
      "5                     storm                0.40           sports   \n",
      "6                light_rain                0.20         festival   \n",
      "7                light_rain                0.14         festival   \n",
      "8                     clear                0.51  community_event   \n",
      "9                     clear                0.57          concert   \n",
      "\n",
      "   days_between_announcement_and_event  organizer_success_rate  \\\n",
      "0                                   10                    0.80   \n",
      "1                                   32                    0.65   \n",
      "2                                   38                    0.56   \n",
      "3                                    5                    0.54   \n",
      "4                                   60                    0.62   \n",
      "5                                   19                    0.80   \n",
      "6                                   43                    0.56   \n",
      "7                                   25                    0.84   \n",
      "8                                   51                    0.87   \n",
      "9                                  109                    0.78   \n",
      "\n",
      "   ticket_price_percentile day_of_week  venue_accessibility_score  \\\n",
      "0                     44.0     weekday                       10.0   \n",
      "1                     10.0     weekday                        6.0   \n",
      "2                     37.0     weekday                        1.0   \n",
      "3                     97.0     weekday                        5.0   \n",
      "4                     64.0     weekend                        5.0   \n",
      "5                     45.0      friday                        9.0   \n",
      "6                     57.0     weekday                        9.0   \n",
      "7                     30.0      friday                        5.0   \n",
      "8                     60.0      friday                        7.0   \n",
      "9                    100.0     weekday                        3.0   \n",
      "\n",
      "   competing_major_events_count  city_tourism_seasonality_index  \\\n",
      "0                             0                           -0.81   \n",
      "1                             0                            0.64   \n",
      "2                             1                           -0.15   \n",
      "3                             2                           -0.08   \n",
      "4                             1                           -0.24   \n",
      "5                             0                            0.70   \n",
      "6                             1                            0.70   \n",
      "7                             1                           -1.00   \n",
      "8                             0                           -0.07   \n",
      "9                             0                           -0.09   \n",
      "\n",
      "  organizer_logo_primary_color  number_of_food_vendors_booked moon_phase  \\\n",
      "0                          red                              9       half   \n",
      "1                        white                             16       full   \n",
      "2                        black                             18       full   \n",
      "3                        black                             11        new   \n",
      "4                        green                              7       full   \n",
      "5                        black                             18       half   \n",
      "6                        white                             10       half   \n",
      "7                          red                             10       full   \n",
      "8                         blue                             12        new   \n",
      "9                          red                             15        new   \n",
      "\n",
      "      outcome  \n",
      "0  successful  \n",
      "1  successful  \n",
      "2   undersold  \n",
      "3   undersold  \n",
      "4   undersold  \n",
      "5   cancelled  \n",
      "6   undersold  \n",
      "7   undersold  \n",
      "8   cancelled  \n",
      "9  successful  \n",
      "\n",
      "Outcome distribution:\n",
      "outcome\n",
      "undersold     0.53\n",
      "successful    0.39\n",
      "cancelled     0.08\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "OUTCOMES = [\"cancelled\", \"undersold\", \"successful\"]\n",
    "\n",
    "# Categorical domains (keep consistent with the tree)\n",
    "WEATHER_LEVELS = [\"clear\", \"light_rain\", \"heavy_rain\", \"storm\"]\n",
    "EVENT_TYPES = [\"concert\", \"sports\", \"festival\", \"community_event\", \"exhibition\"]\n",
    "DAY_OF_WEEK = [\"weekday\", \"friday\", \"weekend\"]\n",
    "LOGO_COLORS = [\"red\", \"blue\", \"green\", \"black\", \"white\", \"yellow\"]\n",
    "MOON_PHASES = [\"new\", \"half\", \"full\"]\n",
    "\n",
    "def _clip01(x):\n",
    "    return np.clip(x, 0.0, 1.0)\n",
    "\n",
    "def _determine_outcome(row):\n",
    "    \"\"\"\n",
    "    Implements the EXACT causal decision tree described in the previous message.\n",
    "    Outcomes: cancelled / undersold / successful\n",
    "    \"\"\"\n",
    "    w = row[\"weather_forecast_severity\"]\n",
    "    et = row[\"event_type\"]\n",
    "    org = row[\"organizer_success_rate\"]\n",
    "    ts = row[\"ticket_sales_ratio\"]\n",
    "    lead = row[\"days_between_announcement_and_event\"]\n",
    "    acc = row[\"venue_accessibility_score\"]\n",
    "    pricep = row[\"ticket_price_percentile\"]\n",
    "    comp = row[\"competing_major_events_count\"]\n",
    "    dow = row[\"day_of_week\"]\n",
    "    tour = row[\"city_tourism_seasonality_index\"]\n",
    "\n",
    "    # --- 1) Safety / feasibility gate ---\n",
    "    # Node A\n",
    "    if w == \"storm\":\n",
    "        return \"cancelled\"\n",
    "\n",
    "    # Node B / D\n",
    "    if w == \"heavy_rain\":\n",
    "        if et in [\"festival\", \"community_event\"]:\n",
    "            # Node D\n",
    "            if org < 0.5:\n",
    "                return \"cancelled\"\n",
    "            # else go to Node C\n",
    "\n",
    "    # --- 2) Demand gate ---\n",
    "    # Node C\n",
    "    if ts < 0.35:\n",
    "        # --- 3) Low-sales pathway ---\n",
    "        # Node E\n",
    "        if lead < 7:\n",
    "            # Node H\n",
    "            if acc < 4:\n",
    "                # Node I\n",
    "                if pricep > 80:\n",
    "                    return \"undersold\"\n",
    "                else:\n",
    "                    # Node J\n",
    "                    if comp >= 2:\n",
    "                        return \"undersold\"\n",
    "                    else:\n",
    "                        # Node K (re-check)\n",
    "                        if w == \"heavy_rain\" and et in [\"festival\", \"community_event\"]:\n",
    "                            return \"cancelled\"\n",
    "                        else:\n",
    "                            return \"undersold\"\n",
    "            else:\n",
    "                return \"undersold\"\n",
    "        else:\n",
    "            return \"undersold\"\n",
    "\n",
    "    elif 0.35 <= ts <= 0.75:\n",
    "        # --- 4) Mid-sales pathway ---\n",
    "        # Node F\n",
    "        if dow in [\"weekend\", \"friday\"]:\n",
    "            # Node L\n",
    "            if tour > 0:\n",
    "                # Node N\n",
    "                if org >= 0.6:\n",
    "                    return \"successful\"\n",
    "                else:\n",
    "                    return \"undersold\"\n",
    "            else:\n",
    "                # Node M\n",
    "                if comp >= 1:\n",
    "                    return \"undersold\"\n",
    "                else:\n",
    "                    # Node N\n",
    "                    if org >= 0.6:\n",
    "                        return \"successful\"\n",
    "                    else:\n",
    "                        return \"undersold\"\n",
    "        else:\n",
    "            # Node M\n",
    "            if comp >= 1:\n",
    "                return \"undersold\"\n",
    "            else:\n",
    "                # Node N\n",
    "                if org >= 0.6:\n",
    "                    return \"successful\"\n",
    "                else:\n",
    "                    return \"undersold\"\n",
    "\n",
    "    else:  # ts > 0.75\n",
    "        # --- 5) High-sales pathway ---\n",
    "        # Node G\n",
    "        if acc >= 4:\n",
    "            # Node O\n",
    "            if et in [\"sports\", \"concert\"]:\n",
    "                return \"successful\"\n",
    "            else:\n",
    "                # Node Q\n",
    "                if w == \"heavy_rain\" and et in [\"festival\", \"community_event\"]:\n",
    "                    return \"undersold\"\n",
    "                else:\n",
    "                    return \"successful\"\n",
    "        else:\n",
    "            # Node P\n",
    "            if dow == \"weekday\":\n",
    "                return \"undersold\"\n",
    "            else:\n",
    "                # Node O\n",
    "                if et in [\"sports\", \"concert\"]:\n",
    "                    return \"successful\"\n",
    "                else:\n",
    "                    # Node Q\n",
    "                    if w == \"heavy_rain\" and et in [\"festival\", \"community_event\"]:\n",
    "                        return \"undersold\"\n",
    "                    else:\n",
    "                        return \"successful\"\n",
    "\n",
    "def _apply_label_noise(y, rng, noise_rate=0.03):\n",
    "    \"\"\"\n",
    "    With probability `noise_rate`, replace label with a different random class.\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype=object)\n",
    "    flip = rng.random(len(y)) < noise_rate\n",
    "    if flip.any():\n",
    "        for i in np.where(flip)[0]:\n",
    "            others = [c for c in OUTCOMES if c != y[i]]\n",
    "            y[i] = rng.choice(others)\n",
    "    return y\n",
    "\n",
    "def generate_outdoor_event_dataset(n=5000, seed=0, noise_rate=0.03):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # --- Generate features (distributions chosen to be plausible; the TREE defines the labels) ---\n",
    "    weather = rng.choice(WEATHER_LEVELS, size=n, p=[0.55, 0.25, 0.15, 0.05])\n",
    "    event_type = rng.choice(EVENT_TYPES, size=n, p=[0.25, 0.20, 0.25, 0.20, 0.10])\n",
    "    day_of_week = rng.choice(DAY_OF_WEEK, size=n, p=[0.55, 0.15, 0.30])\n",
    "\n",
    "    # Numeric features\n",
    "    ticket_sales_ratio = _clip01(rng.beta(2.2, 2.0, size=n))  # center-ish, [0,1]\n",
    "    organizer_success_rate = _clip01(rng.beta(5.0, 2.2, size=n))  # skew higher\n",
    "    days_between_announcement_and_event = np.clip(\n",
    "        rng.lognormal(mean=np.log(20), sigma=0.6, size=n).round().astype(int),\n",
    "        0, 180\n",
    "    )\n",
    "\n",
    "    venue_accessibility_score = np.clip(rng.normal(loc=6.0, scale=2.0, size=n), 1, 10)\n",
    "    ticket_price_percentile = np.clip(rng.normal(loc=55, scale=25, size=n), 0, 100)\n",
    "    competing_major_events_count = np.clip(rng.poisson(lam=0.7, size=n), 0, 6)\n",
    "    city_tourism_seasonality_index = np.clip(rng.normal(loc=0.0, scale=0.5, size=n), -1, 1)\n",
    "\n",
    "    # Almost-irrelevant / weakly-related (generated independently)\n",
    "    organizer_logo_primary_color = rng.choice(LOGO_COLORS, size=n)\n",
    "    number_of_food_vendors_booked = np.clip(rng.poisson(lam=12, size=n), 0, 80)\n",
    "    moon_phase = rng.choice(MOON_PHASES, size=n, p=[0.33, 0.34, 0.33])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"weather_forecast_severity\": weather,\n",
    "        \"ticket_sales_ratio\": np.round(ticket_sales_ratio,2),\n",
    "        \"event_type\": event_type,\n",
    "        \"days_between_announcement_and_event\": days_between_announcement_and_event,\n",
    "        \"organizer_success_rate\": np.round(organizer_success_rate,2),\n",
    "        \"ticket_price_percentile\": np.round(ticket_price_percentile,0),\n",
    "        \"day_of_week\": day_of_week,\n",
    "        \"venue_accessibility_score\": np.round(venue_accessibility_score,0),\n",
    "        \"competing_major_events_count\": competing_major_events_count,\n",
    "        \"city_tourism_seasonality_index\": np.round(city_tourism_seasonality_index,2),\n",
    "        \"organizer_logo_primary_color\": organizer_logo_primary_color,\n",
    "        \"number_of_food_vendors_booked\": number_of_food_vendors_booked,\n",
    "        \"moon_phase\": moon_phase,\n",
    "    })\n",
    "\n",
    "    # --- Apply the exact tree to create the label ---\n",
    "    y = [ _determine_outcome(row) for _, row in df.iterrows() ]\n",
    "\n",
    "    # --- Add 3% stochastic noise (label flipping) ---\n",
    "    y = _apply_label_noise(y, rng, noise_rate=noise_rate)\n",
    "    df[\"outcome\"] = y\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = generate_outdoor_event_dataset(n=20000, seed=42, noise_rate=0.05)\n",
    "    print(df.head(10))\n",
    "    print(\"\\nOutcome distribution:\")\n",
    "    print(df[\"outcome\"].value_counts(normalize=True).round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74579377-6ab1-474f-825c-d7f8b5b72973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('outdoor.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11d773e7-836b-4237-b737-178ad2334a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.918,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40c7a63b-837b-478d-ae57-b98cc47645ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FunctionalIndependence  ADL_Limitations MaritalStatus  AdultChildrenNearby  \\\n",
      "0            independent                1      divorced                    1   \n",
      "1       needs_assistance                2       widowed                    0   \n",
      "2              dependent                2       widowed                    1   \n",
      "3            independent                0       married                    0   \n",
      "4       needs_assistance                0       married                    0   \n",
      "\n",
      "   RecentHospitalization12m IncomeTier     HousingType SelfRatedHealth  \\\n",
      "0                         0        mid           owned            good   \n",
      "1                         0       high           owned            poor   \n",
      "2                         0        mid  public_housing            poor   \n",
      "3                         1        low  public_housing            poor   \n",
      "4                         0        mid           owned            good   \n",
      "\n",
      "  AgeGroup UrbanRural SocialClubParticipation  PetOwnership PreferredTVGenre  \\\n",
      "0    75-84      urban                  weekly             1            drama   \n",
      "1      85+      urban                  weekly             1           sports   \n",
      "2    75-84      rural                  weekly             0            drama   \n",
      "3    65-74      urban                  weekly             1            drama   \n",
      "4    65-74      urban                 monthly             1             news   \n",
      "\n",
      "        LivingArrangement  \n",
      "0    With another elderly  \n",
      "1            Living alone  \n",
      "2  With younger caretaker  \n",
      "3    With another elderly  \n",
      "4    With another elderly  \n",
      "\n",
      "Class distribution:\n",
      "LivingArrangement\n",
      "With another elderly      0.470\n",
      "With younger caretaker    0.354\n",
      "Living alone              0.176\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Saved to elderly_living_arrangement_synth.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def synthesize_elderly_living_arrangement(\n",
    "    n: int = 5000,\n",
    "    seed: int = 42,\n",
    "    add_label_noise: float = 0.08,   # chance to randomly flip label to a neighboring plausible class\n",
    "    add_feature_noise: float = 0.05, # small stochasticity inside the tree gates\n",
    ") -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # --- Helper samplers ---\n",
    "    def sample_categorical(choices, probs, size):\n",
    "        return rng.choice(choices, size=size, p=np.array(probs) / np.sum(probs))\n",
    "\n",
    "    # Age group\n",
    "    age_group = sample_categorical(\n",
    "        [\"65-74\", \"75-84\", \"85+\"],\n",
    "        [0.50, 0.35, 0.15],\n",
    "        n\n",
    "    )\n",
    "\n",
    "    # Marital status (age-dependent)\n",
    "    marital = np.empty(n, dtype=object)\n",
    "    for i, ag in enumerate(age_group):\n",
    "        if ag == \"65-74\":\n",
    "            marital[i] = sample_categorical(\n",
    "                [\"married\", \"widowed\", \"divorced\", \"never_married\"], [0.62, 0.20, 0.12, 0.06], 1\n",
    "            )[0]\n",
    "        elif ag == \"75-84\":\n",
    "            marital[i] = sample_categorical(\n",
    "                [\"married\", \"widowed\", \"divorced\", \"never_married\"], [0.48, 0.38, 0.10, 0.04], 1\n",
    "            )[0]\n",
    "        else:  # 85+\n",
    "            marital[i] = sample_categorical(\n",
    "                [\"married\", \"widowed\", \"divorced\", \"never_married\"], [0.25, 0.65, 0.07, 0.03], 1\n",
    "            )[0]\n",
    "\n",
    "    spouse_present = (marital == \"married\").astype(int)\n",
    "\n",
    "    # Adult children nearby (depends on urban/rural mildly)\n",
    "    urban = sample_categorical([\"urban\", \"rural\"], [0.78, 0.22], n)\n",
    "    adult_child_nearby = np.where(\n",
    "        urban == \"urban\",\n",
    "        rng.binomial(1, 0.62, n),\n",
    "        rng.binomial(1, 0.70, n)\n",
    "    )\n",
    "\n",
    "    # Income tier\n",
    "    income_tier = sample_categorical([\"low\", \"mid\", \"high\"], [0.45, 0.45, 0.10], n)\n",
    "\n",
    "    # Housing type (depends on income a bit)\n",
    "    housing = np.empty(n, dtype=object)\n",
    "    for i, tier in enumerate(income_tier):\n",
    "        if tier == \"low\":\n",
    "            housing[i] = sample_categorical(\n",
    "                [\"public_housing\", \"rental\", \"owned\", \"senior_housing\"], [0.55, 0.25, 0.12, 0.08], 1\n",
    "            )[0]\n",
    "        elif tier == \"mid\":\n",
    "            housing[i] = sample_categorical(\n",
    "                [\"owned\", \"public_housing\", \"rental\", \"senior_housing\"], [0.55, 0.18, 0.22, 0.05], 1\n",
    "            )[0]\n",
    "        else:  # high\n",
    "            housing[i] = sample_categorical(\n",
    "                [\"owned\", \"rental\", \"senior_housing\", \"public_housing\"], [0.72, 0.20, 0.07, 0.01], 1\n",
    "            )[0]\n",
    "\n",
    "    # Care need variables: ADL (0-6), IADL (0-8), Functional status\n",
    "    # Generate a latent \"frailty\" from age group, then map to ADL/IADL/Functional.\n",
    "    frailty_base = np.where(age_group == \"65-74\", 0.15, np.where(age_group == \"75-84\", 0.35, 0.65))\n",
    "    frailty = np.clip(rng.normal(frailty_base, 0.20), 0, 1)\n",
    "\n",
    "    # ADL as binomial with frailty\n",
    "    adl = rng.binomial(6, np.clip(frailty, 0.02, 0.98), n)\n",
    "    # IADL slightly higher sensitivity than ADL\n",
    "    iadl = rng.binomial(8, np.clip(frailty + 0.10, 0.02, 0.98), n)\n",
    "\n",
    "    functional = np.empty(n, dtype=object)\n",
    "    for i in range(n):\n",
    "        # Probabilities tied to frailty and ADL\n",
    "        f = frailty[i]\n",
    "        a = adl[i]\n",
    "        p_dep = np.clip(0.05 + 0.10 * (a >= 4) + 0.55 * f, 0, 0.90)\n",
    "        p_need = np.clip(0.20 + 0.25 * (a >= 2) + 0.25 * f, 0, 0.95)\n",
    "        # Normalize for {independent, needs_assistance, dependent}\n",
    "        p_dependent = min(p_dep, 0.85)\n",
    "        p_needs = min(max(p_need - p_dependent, 0.05), 0.90)\n",
    "        p_ind = max(1.0 - p_dependent - p_needs, 0.02)\n",
    "        probs = np.array([p_ind, p_needs, p_dependent])\n",
    "        probs = probs / probs.sum()\n",
    "        functional[i] = rng.choice([\"independent\", \"needs_assistance\", \"dependent\"], p=probs)\n",
    "\n",
    "    # Recent hospitalization (depends on frailty/ADL)\n",
    "    recent_hosp = rng.binomial(\n",
    "        1,\n",
    "        np.clip(0.10 + 0.08 * (adl >= 2) + 0.25 * frailty, 0.05, 0.65),\n",
    "        n\n",
    "    )\n",
    "\n",
    "    # Less relevant / plausible but weak features\n",
    "    self_rated_health = np.empty(n, dtype=object)\n",
    "    for i in range(n):\n",
    "        # correlated with frailty but noisy\n",
    "        f = frailty[i]\n",
    "        probs = np.array([max(0.10, 1.0 - 1.2 * f), 0.25 + 0.6 * f, 0.10 + 0.6 * f])\n",
    "        probs = np.clip(probs, 0.02, None)\n",
    "        probs = probs / probs.sum()\n",
    "        self_rated_health[i] = rng.choice([\"good\", \"fair\", \"poor\"], p=probs)\n",
    "\n",
    "    # Almost irrelevant but plausible\n",
    "    social_club = sample_categorical([\"weekly\", \"monthly\", \"rarely\"], [0.22, 0.28, 0.50], n)\n",
    "    pet_owner = rng.binomial(1, 0.18, n)\n",
    "    tv_genre = sample_categorical([\"news\", \"drama\", \"variety\", \"sports\"], [0.45, 0.25, 0.20, 0.10], n)\n",
    "\n",
    "    # --- Decision tree labeling logic (from earlier message) ---\n",
    "    labels = np.empty(n, dtype=object)\n",
    "\n",
    "    def maybe(p):\n",
    "        return rng.random() < p\n",
    "\n",
    "    for i in range(n):\n",
    "        ADL = adl[i]\n",
    "        IADL = iadl[i]\n",
    "        Functional = functional[i]\n",
    "        RecentHosp = recent_hosp[i]\n",
    "        SpousePresent = spouse_present[i]\n",
    "        AdultChildNearby = adult_child_nearby[i]\n",
    "        IncomeTier = income_tier[i]\n",
    "        HousingType = housing[i]\n",
    "\n",
    "        # Node 1: High care need?\n",
    "        high_need = (Functional == \"dependent\") or (ADL >= 4)\n",
    "        if maybe(add_feature_noise):\n",
    "            # small random perturbation to avoid hard boundaries\n",
    "            high_need = high_need or (ADL == 3 and RecentHosp == 1 and maybe(0.4))\n",
    "\n",
    "        if high_need:\n",
    "            # Node 2: Younger caretaker availability?\n",
    "            if AdultChildNearby == 1:\n",
    "                label = \"With younger caretaker\"\n",
    "            else:\n",
    "                # Node 3: Same-age cohabitation possible?\n",
    "                if SpousePresent == 1:\n",
    "                    label = \"With another elderly\"\n",
    "                else:\n",
    "                    # Node 4: proxy caretaker via resources / senior housing\n",
    "                    if (IncomeTier == \"high\") or (HousingType == \"senior_housing\"):\n",
    "                        label = \"With younger caretaker\"\n",
    "                    else:\n",
    "                        label = \"With another elderly\"\n",
    "        else:\n",
    "            # Node 5: Moderate care need / transitional risk?\n",
    "            moderate_need = (Functional == \"needs_assistance\") or (ADL in [2, 3]) or (IADL >= 4) or (RecentHosp == 1)\n",
    "            if maybe(add_feature_noise):\n",
    "                moderate_need = moderate_need or (ADL == 1 and IADL >= 5 and maybe(0.35))\n",
    "\n",
    "            if moderate_need:\n",
    "                # Node 6: Spouse present?\n",
    "                if SpousePresent == 1:\n",
    "                    label = \"With another elderly\"\n",
    "                else:\n",
    "                    # Node 7: Adult child nearby?\n",
    "                    if AdultChildNearby == 1:\n",
    "                        label = \"With younger caretaker\"\n",
    "                    else:\n",
    "                        # Node 8: Housing/income pushes away from living alone\n",
    "                        if (HousingType in [\"senior_housing\", \"public_housing\"]) or (IncomeTier == \"low\"):\n",
    "                            label = \"With another elderly\"\n",
    "                        else:\n",
    "                            label = \"Living alone\"\n",
    "            else:\n",
    "                # Node 9: Low care need\n",
    "                if SpousePresent == 1:\n",
    "                    label = \"With another elderly\"\n",
    "                else:\n",
    "                    # Node 10: Independent and no spouse\n",
    "                    if AdultChildNearby == 1 and ((age_group[i] == \"85+\") or (RecentHosp == 1)):\n",
    "                        label = \"With younger caretaker\"\n",
    "                    else:\n",
    "                        label = \"Living alone\"\n",
    "\n",
    "        # Optional: label noise (flip to a plausible alternative)\n",
    "        if maybe(add_label_noise):\n",
    "            if label == \"Living alone\":\n",
    "                label = rng.choice([\"With another elderly\", \"With younger caretaker\"], p=[0.75, 0.25])\n",
    "            elif label == \"With another elderly\":\n",
    "                label = rng.choice([\"Living alone\", \"With younger caretaker\"], p=[0.55, 0.45])\n",
    "            else:  # With younger caretaker\n",
    "                label = rng.choice([\"With another elderly\", \"Living alone\"], p=[0.85, 0.15])\n",
    "\n",
    "        labels[i] = label\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        # Highly relevant\n",
    "        \"FunctionalIndependence\": functional,\n",
    "        \"ADL_Limitations\": adl,\n",
    "        \"MaritalStatus\": marital,\n",
    "        \"AdultChildrenNearby\": adult_child_nearby,\n",
    "        \"RecentHospitalization12m\": recent_hosp,\n",
    "\n",
    "        # Less relevant\n",
    "        \"IncomeTier\": income_tier,\n",
    "        \"HousingType\": housing,\n",
    "        \"SelfRatedHealth\": self_rated_health,\n",
    "        \"AgeGroup\": age_group,\n",
    "        \"UrbanRural\": urban,\n",
    "\n",
    "        # Almost irrelevant but plausible\n",
    "        \"SocialClubParticipation\": social_club,\n",
    "        \"PetOwnership\": pet_owner,\n",
    "        \"PreferredTVGenre\": tv_genre,\n",
    "\n",
    "\n",
    "        # Label\n",
    "        \"LivingArrangement\": labels\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = synthesize_elderly_living_arrangement(n=1000, seed=7)\n",
    "    print(df.head())\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(df[\"LivingArrangement\"].value_counts(normalize=True).round(3))\n",
    "    df.to_csv(\"elderly_living_arrangement_synth.csv\", index=False)\n",
    "    print(\"\\nSaved to elderly_living_arrangement_synth.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "888acf33-e240-425b-84b8-57077ddca38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_verification_match_score  contact_overlap_known_fraud_network  \\\n",
      "0                             0.7890                                    0   \n",
      "1                             0.8195                                    0   \n",
      "2                             0.8411                                    0   \n",
      "3                             0.2333                                    1   \n",
      "4                             0.7578                                    0   \n",
      "\n",
      "   geo_ip_consistency_flag  device_account_uniqueness_30d  \\\n",
      "0                        1                              0   \n",
      "1                        1                              0   \n",
      "2                        0                              0   \n",
      "3                        0                              2   \n",
      "4                        0                              0   \n",
      "\n",
      "   application_velocity_24h  loan_amount_income_ratio  \\\n",
      "0                         0                     4.573   \n",
      "1                         0                     1.818   \n",
      "2                         0                     1.384   \n",
      "3                         2                     2.276   \n",
      "4                         0                     1.368   \n",
      "\n",
      "   bank_account_age_months employment_type time_of_application  \\\n",
      "0                        2        salaried       early_morning   \n",
      "1                       28      freelancer       early_morning   \n",
      "2                       38        salaried             daytime   \n",
      "3                        1        salaried       early_morning   \n",
      "4                       63        salaried             daytime   \n",
      "\n",
      "   num_emergency_contacts mobile_os  loan_tenure_months preferred_language  \\\n",
      "0                       2   Android                   3            English   \n",
      "1                       1   Android                   6            English   \n",
      "2                       0   Android                   6            English   \n",
      "3                       1   Android                  12            English   \n",
      "4                       1   Android                   3            Spanish   \n",
      "\n",
      "       label  \n",
      "0  Non-fraud  \n",
      "1  Non-fraud  \n",
      "2  Non-fraud  \n",
      "3      Fraud  \n",
      "4  Non-fraud  \n",
      "\n",
      "Class balance:\n",
      " label\n",
      "Non-fraud    0.657\n",
      "Fraud        0.343\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def synthesize_microloan_fraud(\n",
    "    n: int = 10000,\n",
    "    seed: int = 42,\n",
    "    # label noise: flip a fraction of labels after rule-based assignment\n",
    "    label_flip_prob: float = 0.03,\n",
    "    # feature noise: jitter numeric features + randomly flip some binary/cat values\n",
    "    feature_noise_prob: float = 0.05,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Generate base features\n",
    "    # -------------------------\n",
    "    # Highly relevant\n",
    "    # Identity score: mixture to create both good and bad identities\n",
    "    mix = rng.random(n) < 0.25  # 25% suspicious population\n",
    "    identity_score = np.where(\n",
    "        mix,\n",
    "        rng.beta(2.0, 5.5, n),   # lower scores\n",
    "        rng.beta(6.5, 2.0, n)    # higher scores\n",
    "    )\n",
    "    identity_score = np.clip(identity_score, 0.0, 1.0)\n",
    "\n",
    "    # Contact overlap: mostly 0, some >0; more likely in suspicious population\n",
    "    contact_overlap = np.where(\n",
    "        mix,\n",
    "        rng.poisson(0.6, n),\n",
    "        rng.poisson(0.05, n)\n",
    "    )\n",
    "    contact_overlap = np.clip(contact_overlap, 0, 10).astype(int)\n",
    "\n",
    "    # Geo-IP consistency: 1 usually, but suspicious population more likely inconsistent\n",
    "    geo_ip_consistent = np.where(\n",
    "        mix,\n",
    "        (rng.random(n) > 0.35).astype(int),  # 65% consistent\n",
    "        (rng.random(n) > 0.08).astype(int)   # 92% consistent\n",
    "    ).astype(int)\n",
    "\n",
    "    # Device-account uniqueness count: suspicious has higher count\n",
    "    device_account_uniqueness_30d = np.where(\n",
    "        mix,\n",
    "        rng.poisson(2.2, n),\n",
    "        rng.poisson(0.3, n)\n",
    "    )\n",
    "    device_account_uniqueness_30d = np.clip(device_account_uniqueness_30d, 0, 20).astype(int)\n",
    "\n",
    "    # Application velocity (24h): suspicious higher\n",
    "    app_velocity_24h = np.where(\n",
    "        mix,\n",
    "        rng.poisson(1.6, n),\n",
    "        rng.poisson(0.15, n)\n",
    "    )\n",
    "    app_velocity_24h = np.clip(app_velocity_24h, 0, 10).astype(int)\n",
    "\n",
    "    # Less relevant\n",
    "    loan_income_ratio = np.where(\n",
    "        rng.random(n) < 0.15,\n",
    "        rng.uniform(2.0, 5.0, n),\n",
    "        rng.uniform(0.2, 2.5, n)\n",
    "    )\n",
    "\n",
    "    bank_account_age_months = np.where(\n",
    "        rng.random(n) < 0.18,\n",
    "        rng.integers(0, 3, n),          # new-ish\n",
    "        rng.integers(3, 72, n)          # older\n",
    "    ).astype(int)\n",
    "\n",
    "    employment_types = np.array([\"salaried\", \"freelancer\", \"self_employed\", \"unemployed\"])\n",
    "    employment_type = rng.choice(\n",
    "        employment_types,\n",
    "        size=n,\n",
    "        p=[0.52, 0.22, 0.18, 0.08]\n",
    "    )\n",
    "\n",
    "    time_buckets = np.array([\"daytime\", \"late_night\", \"early_morning\"])\n",
    "    time_of_application = rng.choice(time_buckets, size=n, p=[0.72, 0.18, 0.10])\n",
    "\n",
    "    emergency_contacts = np.clip(rng.poisson(2.0, n), 0, 8).astype(int)\n",
    "\n",
    "    # Almost irrelevant but seemingly related\n",
    "    mobile_os = rng.choice(np.array([\"Android\", \"iOS\"]), size=n, p=[0.78, 0.22])\n",
    "    loan_tenure_months = rng.choice(np.array([1, 2, 3, 6, 9, 12]), size=n, p=[0.15, 0.15, 0.20, 0.25, 0.10, 0.15]).astype(int)\n",
    "    preferred_language = rng.choice(np.array([\"English\", \"Spanish\", \"Chinese\", \"Hindi\", \"other\"]), size=n, p=[0.55, 0.13, 0.08, 0.12, 0.12])\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 2) Add feature noise (optional)\n",
    "    # -----------------------------------\n",
    "    # Numeric jitter\n",
    "    jitter_mask = rng.random(n) < feature_noise_prob\n",
    "    identity_score[jitter_mask] = np.clip(identity_score[jitter_mask] + rng.normal(0, 0.06, jitter_mask.sum()), 0, 1)\n",
    "\n",
    "    jitter_mask = rng.random(n) < feature_noise_prob\n",
    "    loan_income_ratio[jitter_mask] = np.clip(loan_income_ratio[jitter_mask] + rng.normal(0, 0.25, jitter_mask.sum()), 0.05, 6.0)\n",
    "\n",
    "    # Flip some binary\n",
    "    flip_mask = rng.random(n) < (feature_noise_prob * 0.6)\n",
    "    geo_ip_consistent[flip_mask] = 1 - geo_ip_consistent[flip_mask]\n",
    "\n",
    "    # Perturb some counts\n",
    "    def perturb_counts(arr, p=feature_noise_prob, max_add=2, max_val=None):\n",
    "        m = rng.random(arr.shape[0]) < p\n",
    "        delta = rng.integers(-max_add, max_add + 1, m.sum())\n",
    "        out = arr.copy()\n",
    "        out[m] = out[m] + delta\n",
    "        out = np.clip(out, 0, max_val if max_val is not None else out.max())\n",
    "        return out.astype(int)\n",
    "\n",
    "    contact_overlap = perturb_counts(contact_overlap, p=feature_noise_prob, max_add=1, max_val=10)\n",
    "    device_account_uniqueness_30d = perturb_counts(device_account_uniqueness_30d, p=feature_noise_prob, max_add=2, max_val=20)\n",
    "    app_velocity_24h = perturb_counts(app_velocity_24h, p=feature_noise_prob, max_add=1, max_val=10)\n",
    "    bank_account_age_months = perturb_counts(bank_account_age_months, p=feature_noise_prob, max_add=2, max_val=120)\n",
    "    emergency_contacts = perturb_counts(emergency_contacts, p=feature_noise_prob, max_add=1, max_val=10)\n",
    "\n",
    "    # Flip some categorical values (small probability)\n",
    "    def flip_cats(arr, choices, p=feature_noise_prob * 0.35):\n",
    "        m = rng.random(arr.shape[0]) < p\n",
    "        out = arr.copy()\n",
    "        out[m] = rng.choice(choices, size=m.sum())\n",
    "        return out\n",
    "\n",
    "    employment_type = flip_cats(employment_type, employment_types)\n",
    "    time_of_application = flip_cats(time_of_application, time_buckets)\n",
    "    mobile_os = flip_cats(mobile_os, np.array([\"Android\", \"iOS\"]))\n",
    "    preferred_language = flip_cats(preferred_language, np.array([\"English\", \"Spanish\", \"Chinese\", \"Hindi\", \"other\"]))\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 3) Label generation via the tree\n",
    "    # -----------------------------------\n",
    "    label = np.array([\"Non-fraud\"] * n, dtype=object)\n",
    "\n",
    "    # Helper booleans\n",
    "    id_low = identity_score < 0.65\n",
    "    overlap_pos = contact_overlap > 0\n",
    "    geo_bad = geo_ip_consistent == 0\n",
    "\n",
    "    # Branch: identity_score < 0.65\n",
    "    # If overlap > 0 => Fraud\n",
    "    label[id_low & overlap_pos] = \"Fraud\"\n",
    "\n",
    "    # If overlap == 0:\n",
    "    #   if geo bad => Fraud\n",
    "    label[id_low & (~overlap_pos) & geo_bad] = \"Fraud\"\n",
    "\n",
    "    #   else geo good:\n",
    "    #       if device_uniqueness >= 3 => Fraud\n",
    "    cond = id_low & (~overlap_pos) & (~geo_bad) & (device_account_uniqueness_30d >= 3)\n",
    "    label[cond] = \"Fraud\"\n",
    "\n",
    "    #       else:\n",
    "    #           if velocity >= 2 => Fraud else Non-fraud\n",
    "    cond = id_low & (~overlap_pos) & (~geo_bad) & (device_account_uniqueness_30d < 3) & (app_velocity_24h >= 2)\n",
    "    label[cond] = \"Fraud\"\n",
    "\n",
    "    # Branch: identity_score >= 0.65\n",
    "    # If overlap > 0 => Fraud\n",
    "    label[(~id_low) & overlap_pos] = \"Fraud\"\n",
    "\n",
    "    # If overlap == 0:\n",
    "    #   if geo bad:\n",
    "    #       if device_uniqueness >= 2 => Fraud else Non-fraud\n",
    "    cond = (~id_low) & (~overlap_pos) & geo_bad & (device_account_uniqueness_30d >= 2)\n",
    "    label[cond] = \"Fraud\"\n",
    "\n",
    "    #   else geo good:\n",
    "    #       if device_uniqueness >= 3 => Fraud\n",
    "    cond = (~id_low) & (~overlap_pos) & (~geo_bad) & (device_account_uniqueness_30d >= 3)\n",
    "    label[cond] = \"Fraud\"\n",
    "\n",
    "    #       else:\n",
    "    #           if velocity >= 3 => Fraud else go to tie-breakers\n",
    "    high_velocity = (~id_low) & (~overlap_pos) & (~geo_bad) & (device_account_uniqueness_30d < 3) & (app_velocity_24h >= 3)\n",
    "    label[high_velocity] = \"Fraud\"\n",
    "\n",
    "    # Tie-breaker zone for the remaining subset:\n",
    "    tie = (~id_low) & (~overlap_pos) & (~geo_bad) & (device_account_uniqueness_30d < 3) & (app_velocity_24h < 3)\n",
    "\n",
    "    # (6) loan_income_ratio >= 2.5 ?\n",
    "    t1 = tie & (loan_income_ratio >= 2.5)\n",
    "    # (7) bank_account_age < 2 months ? => Fraud else Non-fraud\n",
    "    label[t1 & (bank_account_age_months < 2)] = \"Fraud\"\n",
    "    label[t1 & (bank_account_age_months >= 2)] = \"Non-fraud\"\n",
    "\n",
    "    # else loan_income_ratio < 2.5:\n",
    "    t2 = tie & (loan_income_ratio < 2.5)\n",
    "    # (8) employment ∈ {unemployed, gig} ?\n",
    "    emp_risky = np.isin(employment_type, [\"unemployed\", \"gig\"])\n",
    "    # (9) time ∈ {late_night, early_morning} ? => Fraud else Non-fraud\n",
    "    nightish = np.isin(time_of_application, [\"late_night\", \"early_morning\"])\n",
    "    label[t2 & emp_risky & nightish] = \"Fraud\"\n",
    "    label[t2 & emp_risky & (~nightish)] = \"Non-fraud\"\n",
    "    label[t2 & (~emp_risky)] = \"Non-fraud\"\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 4) Add label noise (flip some labels)\n",
    "    # -----------------------------------\n",
    "    flip = rng.random(n) < label_flip_prob\n",
    "    label[flip] = np.where(label[flip] == \"Fraud\", \"Non-fraud\", \"Fraud\")\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 5) Build dataframe\n",
    "    # -----------------------------------\n",
    "    df = pd.DataFrame({\n",
    "        # Highly relevant\n",
    "        \"identity_verification_match_score\": identity_score.round(4),\n",
    "        \"contact_overlap_known_fraud_network\": contact_overlap,\n",
    "        \"geo_ip_consistency_flag\": geo_ip_consistent,  # 1 consistent, 0 inconsistent\n",
    "        \"device_account_uniqueness_30d\": device_account_uniqueness_30d,\n",
    "        \"application_velocity_24h\": app_velocity_24h,\n",
    "\n",
    "        # Less relevant\n",
    "        \"loan_amount_income_ratio\": loan_income_ratio.round(3),\n",
    "        \"bank_account_age_months\": bank_account_age_months,\n",
    "        \"employment_type\": employment_type,\n",
    "        \"time_of_application\": time_of_application,\n",
    "        \"num_emergency_contacts\": emergency_contacts,\n",
    "\n",
    "        # Almost irrelevant but seemingly related\n",
    "        \"mobile_os\": mobile_os,\n",
    "        \"loan_tenure_months\": loan_tenure_months,\n",
    "        \"preferred_language\": preferred_language,\n",
    "\n",
    "        # Label\n",
    "        \"label\": label\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = synthesize_microloan_fraud(\n",
    "        n=20000,\n",
    "        seed=7,\n",
    "        label_flip_prob=0.08,\n",
    "        feature_noise_prob=0.06,\n",
    "    )\n",
    "    print(df.head())\n",
    "    print(\"\\nClass balance:\\n\", df[\"label\"].value_counts(normalize=True).round(3))\n",
    "    df.to_csv(\"microloan_fraud_synth.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b048d4e-0350-4d8a-a6b2-6f9bb220e523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_prior_defaults  identity_verification_passed  device_fingerprint_match  \\\n",
      "0                   1                             0                         1   \n",
      "1                   3                             0                         0   \n",
      "2                   0                             1                         0   \n",
      "3                   1                             1                         1   \n",
      "4                   1                             1                         1   \n",
      "\n",
      "   application_velocity_24h  income_to_loan_ratio  account_age_days  \\\n",
      "0                         1                 1.192                29   \n",
      "1                         2                 0.837                13   \n",
      "2                         1                 0.659                20   \n",
      "3                         0                 1.478                26   \n",
      "4                         0                 2.047                32   \n",
      "\n",
      "  employment_type repayment_method  geo_risk_score  previous_loan_count  \\\n",
      "0        salaried         e-wallet           0.496                    1   \n",
      "1   self-employed         e-wallet           0.464                    0   \n",
      "2   self-employed    bank_transfer           0.395                    0   \n",
      "3      unemployed    bank_transfer           0.143                    0   \n",
      "4   self-employed    bank_transfer           0.500                    0   \n",
      "\n",
      "   application_hour mobile_os marketing_campaign_id      label  \n",
      "0                22   Android                    C6      Fraud  \n",
      "1                15   Android                    C1  Non-fraud  \n",
      "2                15   Android                    C3      Fraud  \n",
      "3                16   Android                    C6  Non-fraud  \n",
      "4                20       iOS                    C6  Non-fraud  \n",
      "\n",
      "Class balance:\n",
      "label\n",
      "Fraud        0.591\n",
      "Non-fraud    0.409\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Saved: microloan_fraud_synth.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def synthesize_microloan_fraud(n=5000, seed=42, label_noise=0.03, feature_noise=0.05):\n",
    "    \"\"\"\n",
    "    Generates a synthetic micro-loan fraud dataset with:\n",
    "    - Feature correlations (via shared latent factors)\n",
    "    - A hard decision tree mapping features -> label\n",
    "    - Small noise (both feature noise + label flipping)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1) Latent factors (drive correlations)\n",
    "    # ----------------------------\n",
    "    # fraud_latent: higher -> more likely fraud-like behaviors\n",
    "    fraud_latent = rng.normal(0, 1, n)\n",
    "    # stability_latent: higher -> older accounts, more prior good loans, higher income consistency\n",
    "    stability_latent = rng.normal(0, 1, n)\n",
    "    # geo_latent: higher -> riskier region\n",
    "    geo_latent = rng.normal(0, 1, n)\n",
    "    # marketing_latent: drives campaign + volume spikes (spurious correlation)\n",
    "    marketing_latent = rng.normal(0, 1, n)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2) Generate features with correlations\n",
    "    # ----------------------------\n",
    "    # Highly relevant\n",
    "    # num_prior_defaults correlates negatively with stability, positively with fraud_latent\n",
    "    num_prior_defaults = np.clip(\n",
    "        rng.poisson(lam=np.exp(0.15 + 0.55 * fraud_latent - 0.35 * stability_latent)),\n",
    "        0, 8\n",
    "    ).astype(int)\n",
    "\n",
    "    # identity_verification_passed: more likely to fail with higher fraud_latent and higher geo risk\n",
    "    p_kyc_pass = 1 / (1 + np.exp(1.0 * fraud_latent + 0.6 * geo_latent - 0.3 * stability_latent))\n",
    "    identity_verification_passed = (rng.uniform(0, 1, n) < p_kyc_pass).astype(int)\n",
    "\n",
    "    # device_fingerprint_match: positively with stability, negatively with fraud_latent; also correlated with KYC pass\n",
    "    p_device_match = 1 / (1 + np.exp(0.9 * fraud_latent - 0.8 * stability_latent - 0.5 * identity_verification_passed))\n",
    "    device_fingerprint_match = (rng.uniform(0, 1, n) < p_device_match).astype(int)\n",
    "\n",
    "    # application_velocity_24h: higher with fraud_latent + marketing_latent + geo_latent; lower with stability\n",
    "    base_vel = np.exp(0.5 + 0.9 * fraud_latent + 0.4 * marketing_latent + 0.3 * geo_latent - 0.4 * stability_latent)\n",
    "    application_velocity_24h = np.clip(rng.poisson(lam=base_vel), 0, 20).astype(int)\n",
    "\n",
    "    # income_to_loan_ratio: higher with stability, lower with fraud_latent (fraud requests relatively more)\n",
    "    income_to_loan_ratio = np.clip(\n",
    "        rng.normal(loc=1.2 + 0.45 * stability_latent - 0.35 * fraud_latent, scale=0.25),\n",
    "        0.05, 4.0\n",
    "    )\n",
    "\n",
    "    # Less relevant\n",
    "    # account_age_days correlates strongly with stability\n",
    "    account_age_days = np.clip(\n",
    "        rng.lognormal(mean=3.3 + 0.55 * stability_latent, sigma=0.55),\n",
    "        1, 3650\n",
    "    ).astype(int)\n",
    "\n",
    "    # previous_loan_count correlates with account_age_days + stability; slightly lower with fraud_latent\n",
    "    prev_count_lambda = np.exp(-0.3 + 0.35 * np.log1p(account_age_days) + 0.45 * stability_latent - 0.25 * fraud_latent)\n",
    "    previous_loan_count = np.clip(rng.poisson(lam=prev_count_lambda / 5.0), 0, 30).astype(int)\n",
    "\n",
    "    # employment_type depends on stability (proxy)\n",
    "    # 0: unemployed, 1: self-employed, 2: salaried\n",
    "    emp_score = 0.7 * stability_latent - 0.2 * fraud_latent + rng.normal(0, 0.5, n)\n",
    "    employment_type = np.where(emp_score > 0.6, \"salaried\",\n",
    "                        np.where(emp_score > -0.2, \"self-employed\", \"unemployed\"))\n",
    "\n",
    "    # repayment_method depends weakly on geo + fraud_latent (cash_agent slightly riskier)\n",
    "    rm_score = 0.35 * fraud_latent + 0.25 * geo_latent + rng.normal(0, 0.6, n)\n",
    "    repayment_method = np.where(rm_score > 0.7, \"cash_agent\",\n",
    "                         np.where(rm_score > -0.1, \"e-wallet\", \"bank_transfer\"))\n",
    "\n",
    "    # geo_risk_score: derived from geo_latent + small noise\n",
    "    geo_risk_score = 1 / (1 + np.exp(-(0.9 * geo_latent + 0.2 * fraud_latent + rng.normal(0, 0.4, n))))\n",
    "    geo_risk_score = np.clip(geo_risk_score, 0.0, 1.0)\n",
    "\n",
    "    # Almost irrelevant but seemingly related\n",
    "    application_hour = rng.integers(0, 24, n)\n",
    "\n",
    "    # mobile_os: weak correlation with device match (noisy)\n",
    "    p_ios = np.clip(0.35 + 0.10 * (device_fingerprint_match - 0.5) + rng.normal(0, 0.05, n), 0.05, 0.95)\n",
    "    mobile_os = np.where(rng.uniform(0, 1, n) < p_ios, \"iOS\", \"Android\")\n",
    "\n",
    "    # marketing_campaign_id: correlates with marketing_latent (spurious correlation with velocity)\n",
    "    # create 6 campaigns\n",
    "    campaign_bins = np.digitize(marketing_latent + rng.normal(0, 0.3, n),\n",
    "                                bins=np.quantile(marketing_latent, [1/6, 2/6, 3/6, 4/6, 5/6]))\n",
    "    marketing_campaign_id = np.array([f\"C{b+1}\" for b in campaign_bins])\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3) Add small feature noise (measurement noise)\n",
    "    # ----------------------------\n",
    "    # Numeric noise\n",
    "    income_to_loan_ratio = np.clip(\n",
    "        income_to_loan_ratio + rng.normal(0, feature_noise * 0.2, n),\n",
    "        0.05, 4.0\n",
    "    )\n",
    "    geo_risk_score = np.clip(\n",
    "        geo_risk_score + rng.normal(0, feature_noise * 0.15, n),\n",
    "        0.0, 1.0\n",
    "    )\n",
    "\n",
    "    # Occasionally flip a small fraction of binary features (sensor / pipeline noise)\n",
    "    def flip_binary(x, p):\n",
    "        flip = rng.uniform(0, 1, x.shape[0]) < p\n",
    "        x2 = x.copy()\n",
    "        x2[flip] = 1 - x2[flip]\n",
    "        return x2\n",
    "\n",
    "    identity_verification_passed = flip_binary(identity_verification_passed, feature_noise * 0.25)\n",
    "    device_fingerprint_match = flip_binary(device_fingerprint_match, feature_noise * 0.25)\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4) Decision tree label (hard rules)\n",
    "    # ----------------------------\n",
    "    # Tree (from earlier):\n",
    "    # Node1: identity_verification_passed\n",
    "    #  - 0 -> Node2: application_velocity_24h >=3 => Fraud else Node3\n",
    "    #    Node3: num_prior_defaults >=1 => Fraud else Node3a: geo_risk_score >=0.7 => Fraud else Non-fraud\n",
    "    #  - 1 -> Node4: device_fingerprint_match\n",
    "    #    - 0 -> Node5: application_velocity_24h >=4 => Fraud else Node6\n",
    "    #         Node6: income_to_loan_ratio <0.8 => Fraud else Node6a: account_age_days <14 => Fraud else Non-fraud\n",
    "    #    - 1 -> Node7: num_prior_defaults >=2 => Fraud else Node8\n",
    "    #         Node8: previous_loan_count >=2 => Non-fraud else Node9\n",
    "    #         Node9: income_to_loan_ratio >=1.2 => Non-fraud else Node10\n",
    "    #         Node10: repayment_method == cash_agent => Fraud else Node11\n",
    "    #         Node11: hour in [2..5] => Fraud else Non-fraud\n",
    "\n",
    "    label = np.zeros(n, dtype=int)  # 1=Fraud, 0=Non-fraud\n",
    "\n",
    "    # Left branch: KYC failed\n",
    "    left = identity_verification_passed == 0\n",
    "    left_node2 = left & (application_velocity_24h >= 3)\n",
    "    label[left_node2] = 1\n",
    "\n",
    "    left_node2_else = left & (application_velocity_24h < 3)\n",
    "    left_node3 = left_node2_else & (num_prior_defaults >= 1)\n",
    "    label[left_node3] = 1\n",
    "\n",
    "    left_node3_else = left_node2_else & (num_prior_defaults == 0)\n",
    "    left_node3a = left_node3_else & (geo_risk_score >= 0.7)\n",
    "    label[left_node3a] = 1\n",
    "    # else remains Non-fraud\n",
    "\n",
    "    # Right branch: KYC passed\n",
    "    right = identity_verification_passed == 1\n",
    "\n",
    "    # Device mismatch\n",
    "    dev_mismatch = right & (device_fingerprint_match == 0)\n",
    "    node5 = dev_mismatch & (application_velocity_24h >= 4)\n",
    "    label[node5] = 1\n",
    "\n",
    "    node5_else = dev_mismatch & (application_velocity_24h < 4)\n",
    "    node6 = node5_else & (income_to_loan_ratio < 0.8)\n",
    "    label[node6] = 1\n",
    "\n",
    "    node6_else = node5_else & (income_to_loan_ratio >= 0.8)\n",
    "    node6a = node6_else & (account_age_days < 14)\n",
    "    label[node6a] = 1\n",
    "    # else remains Non-fraud\n",
    "\n",
    "    # Device match\n",
    "    dev_match = right & (device_fingerprint_match == 1)\n",
    "    node7 = dev_match & (num_prior_defaults >= 2)\n",
    "    label[node7] = 1\n",
    "\n",
    "    node7_else = dev_match & (num_prior_defaults < 2)\n",
    "    node8 = node7_else & (previous_loan_count >= 2)\n",
    "    # node8 => Non-fraud (already 0)\n",
    "\n",
    "    node8_else = node7_else & (previous_loan_count < 2)\n",
    "    node9 = node8_else & (income_to_loan_ratio >= 1.2)\n",
    "    # node9 => Non-fraud (already 0)\n",
    "\n",
    "    node9_else = node8_else & (income_to_loan_ratio < 1.2)\n",
    "    node10 = node9_else & (repayment_method == \"cash_agent\")\n",
    "    label[node10] = 1\n",
    "\n",
    "    node10_else = node9_else & (repayment_method != \"cash_agent\")\n",
    "    node11 = node10_else & ((application_hour >= 2) & (application_hour <= 5))\n",
    "    label[node11] = 1\n",
    "    # else remains Non-fraud\n",
    "\n",
    "    # ----------------------------\n",
    "    # 5) Small label noise (flip a small fraction)\n",
    "    # ----------------------------\n",
    "    flip = rng.uniform(0, 1, n) < label_noise\n",
    "    label_noisy = label.copy()\n",
    "    label_noisy[flip] = 1 - label_noisy[flip]\n",
    "\n",
    "    # ----------------------------\n",
    "    # 6) Assemble dataframe\n",
    "    # ----------------------------\n",
    "    df = pd.DataFrame({\n",
    "        # Highly relevant\n",
    "        \"num_prior_defaults\": num_prior_defaults,\n",
    "        \"identity_verification_passed\": identity_verification_passed,\n",
    "        \"device_fingerprint_match\": device_fingerprint_match,\n",
    "        \"application_velocity_24h\": application_velocity_24h,\n",
    "        \"income_to_loan_ratio\": np.round(income_to_loan_ratio, 3),\n",
    "\n",
    "        # Less relevant\n",
    "        \"account_age_days\": account_age_days,\n",
    "        \"employment_type\": employment_type,\n",
    "        \"repayment_method\": repayment_method,\n",
    "        \"geo_risk_score\": np.round(geo_risk_score, 3),\n",
    "        \"previous_loan_count\": previous_loan_count,\n",
    "\n",
    "        # Almost irrelevant\n",
    "        \"application_hour\": application_hour,\n",
    "        \"mobile_os\": mobile_os,\n",
    "        \"marketing_campaign_id\": marketing_campaign_id,\n",
    "\n",
    "        # Label\n",
    "        \"label\": np.where(label_noisy == 1, \"Fraud\", \"Non-fraud\")\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = synthesize_microloan_fraud(n=20000, seed=7, label_noise=0.05, feature_noise=0)\n",
    "    print(df.head())\n",
    "    print(\"\\nClass balance:\")\n",
    "    print(df[\"label\"].value_counts(normalize=True).round(3))\n",
    "    df.to_csv(\"microloan_fraud_synth.csv\", index=False)\n",
    "    print(\"\\nSaved: microloan_fraud_synth.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "263be0c5-f4e0-4037-8374-634ca44f7852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8beff572-8f0a-447c-82b2-36c8f4918cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fraud_encode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2afda533-4467-4693-9f9e-ab1442156a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_prior_defaults</th>\n",
       "      <th>identity_verification_passed</th>\n",
       "      <th>device_fingerprint_match</th>\n",
       "      <th>application_velocity_24h</th>\n",
       "      <th>income_to_loan_ratio</th>\n",
       "      <th>account_age_days</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>repayment_method</th>\n",
       "      <th>geo_risk_score</th>\n",
       "      <th>previous_loan_count</th>\n",
       "      <th>application_hour</th>\n",
       "      <th>mobile_os</th>\n",
       "      <th>marketing_campaign_id</th>\n",
       "      <th>fraud_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.016</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.702</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.055</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.853</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.632</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.776</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.482</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.355</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.578</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.754</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.471</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_prior_defaults  identity_verification_passed  \\\n",
       "0                     1                             1   \n",
       "1                     1                             0   \n",
       "2                     4                             0   \n",
       "3                     3                             1   \n",
       "4                     2                             0   \n",
       "..                  ...                           ...   \n",
       "995                   1                             0   \n",
       "996                   1                             1   \n",
       "997                   0                             1   \n",
       "998                   0                             1   \n",
       "999                   4                             0   \n",
       "\n",
       "     device_fingerprint_match  application_velocity_24h  income_to_loan_ratio  \\\n",
       "0                           1                         0                 2.016   \n",
       "1                           0                         1                 0.953   \n",
       "2                           0                         1                 1.085   \n",
       "3                           0                        11                 0.055   \n",
       "4                           0                         4                 0.853   \n",
       "..                        ...                       ...                   ...   \n",
       "995                         0                         4                 0.632   \n",
       "996                         1                         3                 0.776   \n",
       "997                         1                         1                 1.482   \n",
       "998                         1                         5                 2.355   \n",
       "999                         0                        12                 0.754   \n",
       "\n",
       "     account_age_days  employment_type  repayment_method  geo_risk_score  \\\n",
       "0                  38                1                 2           0.702   \n",
       "1                  26                2                 1           0.355   \n",
       "2                  39                2                 1           0.210   \n",
       "3                  21                3                 1           0.225   \n",
       "4                   8                3                 2           0.656   \n",
       "..                ...              ...               ...             ...   \n",
       "995                31                2                 1           0.698   \n",
       "996                25                1                 2           0.402   \n",
       "997                96                2                 1           0.449   \n",
       "998                95                1                 2           0.578   \n",
       "999                18                3                 1           0.471   \n",
       "\n",
       "     previous_loan_count  application_hour  mobile_os  marketing_campaign_id  \\\n",
       "0                      1                 2          1                      1   \n",
       "1                      1                 2          1                      5   \n",
       "2                      0                 1          2                      2   \n",
       "3                      0                15          2                      3   \n",
       "4                      0                12          1                      4   \n",
       "..                   ...               ...        ...                    ...   \n",
       "995                    1                 3          1                      3   \n",
       "996                    0                 2          1                      1   \n",
       "997                    0                 3          1                      5   \n",
       "998                    1                21          2                      1   \n",
       "999                    1                 2          2                      1   \n",
       "\n",
       "     fraud_label  \n",
       "0              0  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "..           ...  \n",
       "995            1  \n",
       "996            1  \n",
       "997            0  \n",
       "998            0  \n",
       "999            1  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7900d614-9cc2-42b0-93f9-335461d010f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "FEATURES = [\n",
    "    \"identity_verification_passed\",\n",
    "    \"application_velocity_24h\",\n",
    "    \"num_prior_defaults\",\n",
    "    \"geo_risk_score\",\n",
    "    \"device_fingerprint_match\",\n",
    "    \"income_to_loan_ratio\",\n",
    "    \"account_age_days\",\n",
    "    \"previous_loan_count\",\n",
    "    \"repayment_method\",\n",
    "    \"application_hour\",\n",
    "    \"employment_type\",\n",
    "    \"mobile_os\",\n",
    "    \"marketing_campaign_id\"\n",
    "]\n",
    "\n",
    "MAX_RANK = 20\n",
    "\n",
    "\n",
    "def rank_features_by_tree(row):\n",
    "    \"\"\"\n",
    "    Given a single row (pd.Series), return a dict:\n",
    "    {feature_name: rank}\n",
    "    \"\"\"\n",
    "    ranks = {f: MAX_RANK for f in FEATURES}\n",
    "    current_rank = 1\n",
    "\n",
    "    def use(feature):\n",
    "        nonlocal current_rank\n",
    "        if ranks[feature] == MAX_RANK:\n",
    "            ranks[feature] = current_rank\n",
    "            current_rank += 1\n",
    "\n",
    "    # ----- Decision tree traversal -----\n",
    "\n",
    "    # Node 1\n",
    "    use(\"identity_verification_passed\")\n",
    "    if row[\"identity_verification_passed\"] == 0:\n",
    "        # Node 2\n",
    "        use(\"application_velocity_24h\")\n",
    "        if row[\"application_velocity_24h\"] >= 3:\n",
    "            return ranks\n",
    "        # Node 3\n",
    "        use(\"num_prior_defaults\")\n",
    "        if row[\"num_prior_defaults\"] >= 1:\n",
    "            return ranks\n",
    "        # Node 3a\n",
    "        use(\"geo_risk_score\")\n",
    "        return ranks\n",
    "\n",
    "    # identity_verification_passed == 1\n",
    "    # Node 4\n",
    "    use(\"device_fingerprint_match\")\n",
    "    if row[\"device_fingerprint_match\"] == 0:\n",
    "        # Node 5\n",
    "        use(\"application_velocity_24h\")\n",
    "        if row[\"application_velocity_24h\"] >= 4:\n",
    "            return ranks\n",
    "        # Node 6\n",
    "        use(\"income_to_loan_ratio\")\n",
    "        if row[\"income_to_loan_ratio\"] < 0.8:\n",
    "            return ranks\n",
    "        # Node 6a\n",
    "        use(\"account_age_days\")\n",
    "        return ranks\n",
    "\n",
    "    # device_fingerprint_match == 1\n",
    "    # Node 7\n",
    "    use(\"num_prior_defaults\")\n",
    "    if row[\"num_prior_defaults\"] >= 2:\n",
    "        return ranks\n",
    "    # Node 8\n",
    "    use(\"previous_loan_count\")\n",
    "    if row[\"previous_loan_count\"] >= 2:\n",
    "        return ranks\n",
    "    # Node 9\n",
    "    use(\"income_to_loan_ratio\")\n",
    "    if row[\"income_to_loan_ratio\"] >= 1.2:\n",
    "        return ranks\n",
    "    # Node 10\n",
    "    use(\"repayment_method\")\n",
    "    if row[\"repayment_method\"] == \"cash_agent\":\n",
    "        return ranks\n",
    "    # Node 11\n",
    "    use(\"application_hour\")\n",
    "    return ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d163d16e-5b1b-4a28-9770-c46cc185b390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   identity_verification_passed  application_velocity_24h  num_prior_defaults  \\\n",
      "0                             1                        20                   3   \n",
      "1                             1                         2                   3   \n",
      "2                             1                         2                   3   \n",
      "3                             1                         3                  20   \n",
      "4                             1                         2                  20   \n",
      "\n",
      "   geo_risk_score  device_fingerprint_match  income_to_loan_ratio  \\\n",
      "0              20                         2                     5   \n",
      "1              20                        20                    20   \n",
      "2              20                        20                    20   \n",
      "3              20                         2                    20   \n",
      "4              20                        20                    20   \n",
      "\n",
      "   account_age_days  previous_loan_count  repayment_method  application_hour  \\\n",
      "0                20                    4                20                20   \n",
      "1                20                   20                20                20   \n",
      "2                20                   20                20                20   \n",
      "3                20                   20                20                20   \n",
      "4                20                   20                20                20   \n",
      "\n",
      "   employment_type  mobile_os  marketing_campaign_id  \n",
      "0               20         20                     20  \n",
      "1               20         20                     20  \n",
      "2               20         20                     20  \n",
      "3               20         20                     20  \n",
      "4               20         20                     20  \n"
     ]
    }
   ],
   "source": [
    "def compute_instance_feature_ranks(df):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame of shape (n_samples, n_features)\n",
    "    where each cell is the rank for that feature on that instance.\n",
    "    \"\"\"\n",
    "    rank_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        rank_rows.append(rank_features_by_tree(row))\n",
    "    return pd.DataFrame(rank_rows, index=df.index)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "rank_df = compute_instance_feature_ranks(df)\n",
    "\n",
    "print(rank_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82a658be-8b3e-4ace-8d4e-a8a4aa714645",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_df.to_csv('fraud_ranking.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc5853-8d12-44f9-a86f-a32fb29a814b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
